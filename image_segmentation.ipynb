{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation by Clustering\n",
    "\n",
    "**Date Created: 12/6/2020**\n",
    "\n",
    "**The purpose of this notebook is to experiment with image segmentation using clustering algorithms, comparing DyClee's performance against the clustering algorithms implemented in Scikit-Learn that were referenced in the paper:**\n",
    "\n",
    "Nathalie Barbosa Roa, Louise Travé-Massuyès, Victor Hugo Grisales. DyClee: Dynamic clustering for tracking evolving environments. Pattern Recognition, Elsevier, 2019, 94, pp.162-186. 10.1016/j.patcog.2019.05.024 . hal-02135580\n",
    "\n",
    "**NOTE: This notebook is partially informed by the segmentation demonstration on pages 249-251 in:**\n",
    "\n",
    "Aurelien Geron. Hands-on Machine Learning with Scikit-Learn, Keras & Tensorflow: Concepts, Tools, and Techniques to Build Intelligent Systems (Sebastopol, CA: O'Reilly Media, Inc., 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans, AgglomerativeClustering, AffinityPropagation, DBSCAN, Birch\n",
    "from sklearn.datasets import load_sample_images\n",
    "import tensorflow as tf\n",
    "\n",
    "from DyClee.algorithms import SerialDyClee\n",
    "from DyClee.plotting import unpack_snapshots, strip_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize to range 0 - 1.0\n",
    "def normalize(img):\n",
    "    return img.astype(np.float64) / 255.0\n",
    "\n",
    "# Augment with spatial information - pixel location (y, x - aka row, col)\n",
    "# @param img    A NORMALIZED image.\n",
    "def augment_location(img):\n",
    "    shape = img.shape\n",
    "    rows = np.arange(shape[0])\n",
    "    cols = np.arange(shape[1])\n",
    "    yi, xj = np.meshgrid(rows, cols, indexing='ij')\n",
    "    yi = yi.astype(np.float64) / shape[0]\n",
    "    xj = xj.astype(np.float64) / shape[1]\n",
    "    if len(shape) == 2: # Grayscale\n",
    "        return np.stack((yi, xj, img), axis=-1)\n",
    "    else:\n",
    "        yi = np.expand_dims(yi, axis=2)\n",
    "        xj = np.expand_dims(xj, axis=2)\n",
    "        return np.concatenate((yi, xj, img), axis=-1)\n",
    "        \n",
    "    \n",
    "# Flatten to treat pixels as instances\n",
    "def flatten_img(img):\n",
    "    if len(img.shape) == 2: # Grayscale\n",
    "        return img.reshape(img.shape[0] * img.shape[1], 1)\n",
    "    else:\n",
    "        dims = img.shape[-1]\n",
    "        return img.reshape(-1, dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Sample Images from Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_sample_images()\n",
    "china, flower = dataset.images\n",
    "sk_sample_shape = china.shape\n",
    "print(sk_sample_shape)\n",
    "print(china.dtype)\n",
    "fig, ax = plt.subplots(1,2, figsize=(25,25))\n",
    "ax[0].imshow(china)\n",
    "ax[1].imshow(flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_norm = normalize(china)\n",
    "flower_norm = normalize(flower)\n",
    "\n",
    "num_clusters = [2 ** x for x in range(5)]\n",
    "fig, ax = plt.subplots(2, len(num_clusters), figsize=(25, 10))\n",
    "\n",
    "china_flat = flatten_img(china_norm)\n",
    "for i, num in enumerate(num_clusters):\n",
    "    # THIS IS BASED ON THE DEMONSTRATION IN THE GERON BOOK - SEE PAGE 250\n",
    "    china_km = MiniBatchKMeans(n_clusters=num).fit(china_flat)\n",
    "    result = china_km.cluster_centers_[china_km.labels_]\n",
    "    result = result.reshape(china.shape)\n",
    "    ax[0,i].imshow(result)\n",
    "    \n",
    "flower_flat = flatten_img(flower_norm)\n",
    "for i, num in enumerate(num_clusters):\n",
    "    flower_km = MiniBatchKMeans(n_clusters=num).fit(flower_flat)\n",
    "    result = flower_km.cluster_centers_[flower_km.labels_]\n",
    "    result = result.reshape(flower.shape)\n",
    "    ax[1,i].imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmented with Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_aug = augment_location(china_norm)\n",
    "flower_aug = augment_location(flower_norm)\n",
    "\n",
    "num_clusters = [2 ** x for x in range(5)]\n",
    "fig, ax = plt.subplots(2, len(num_clusters), figsize=(25, 10))\n",
    "\n",
    "china_flat = flatten_img(china_aug)\n",
    "for i, num in enumerate(num_clusters):\n",
    "    china_km = MiniBatchKMeans(n_clusters=num).fit(china_flat)\n",
    "    result = china_km.cluster_centers_[china_km.labels_]\n",
    "    print(result.shape)\n",
    "    aug_shape = (china.shape[0], china.shape[1], 5)\n",
    "    result = result.reshape(aug_shape)\n",
    "    result = result[:,:,2:]\n",
    "    ax[0,i].imshow(result)\n",
    "    \n",
    "flower_flat = flatten_img(flower_aug)\n",
    "for i, num in enumerate(num_clusters):\n",
    "    flower_km = MiniBatchKMeans(n_clusters=num).fit(flower_flat)\n",
    "    result = flower_km.cluster_centers_[flower_km.labels_]\n",
    "    aug_shape = (flower.shape[0], flower.shape[1], 5)\n",
    "    result = result.reshape(aug_shape)\n",
    "    result = result[:,:,2:]\n",
    "    ax[1,i].imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DyClee Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING:** Running on even a limited portion of the China image will take quite a while, and the below phi parameter is NOT well-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "china_flat_part = flatten_img(china_aug[:200, :200])\n",
    "\n",
    "context = np.vstack([china_flat_part.min(axis=0), china_flat_part.max(axis=0)])\n",
    "dyclee = SerialDyClee(phi=0.1, context=context, t_global=4000)\n",
    "results = dyclee.run_dataset(data=china_flat_part)\n",
    "results = strip_labels(results)\n",
    "\n",
    "timestamps, snapshots_ordered = unpack_snapshots(dyclee.snapshots)\n",
    "print(snapshots_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'0':0.07780313, '1': 0.98997821, 'Unclassed':0.5}\n",
    "seg_img = np.array([colors[px] for px in results]).reshape(200,200) * 255\n",
    "plt.imshow(seg_img, cmap=\"binary\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "five = mnist[\"data\"][0]\n",
    "five_img = five.reshape(28,28)\n",
    "plt.imshow(five_img, cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "five_img_norm = normalize(five_img)\n",
    "five_flat = flatten_img(five_img_norm)\n",
    "\n",
    "context = np.vstack([five_flat.min(axis=0), five_flat.max(axis=0)])\n",
    "dyclee = SerialDyClee(phi=0.1, context=context, t_global=784)\n",
    "results = dyclee.run_dataset(data=five_flat)\n",
    "results = strip_labels(results)\n",
    "\n",
    "timestamps, snapshots_ordered = unpack_snapshots(dyclee.snapshots)\n",
    "print(snapshots_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = {'0':0.07780313, '1': 0.98997821, 'Unclassed':0.5}\n",
    "seg_img = np.array([colors[px] for px in results]).reshape(28,28) * 255\n",
    "plt.imshow(seg_img, cmap=\"binary\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = {}\n",
    "colors['Unclassed'] = np.array([0,0,0])\n",
    "for i in range (100):\n",
    "    colors[str(i)] = (np.random.default_rng().integers(32, 256, size=(1,3))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird = x_train[6]\n",
    "plt.imshow(bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bird_norm = normalize(bird)\n",
    "bird_norm_aug = augment_location(bird_norm)\n",
    "bird_aug_flat = flatten_img(bird_norm_aug)\n",
    "\n",
    "context = np.vstack([bird_aug_flat.min(axis=0), bird_aug_flat.max(axis=0)])\n",
    "dyclee = SerialDyClee(phi=0.08, context=context, t_global=1024)\n",
    "results = dyclee.run_dataset(data=bird_aug_flat)\n",
    "results = strip_labels(results)\n",
    "\n",
    "timestamps, snapshots_ordered = unpack_snapshots(dyclee.snapshots)\n",
    "print(snapshots_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seg_img = np.vstack([colors[px] for px in results]).reshape(32,32, 3)\n",
    "plt.imshow(seg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "horse = x_train[7]\n",
    "plt.imshow(horse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "horse_norm = normalize(horse)\n",
    "horse_norm_aug = augment_location(horse_norm)\n",
    "horse_aug_flat = flatten_img(horse_norm_aug)\n",
    "\n",
    "context = np.vstack([horse_aug_flat.min(axis=0), horse_aug_flat.max(axis=0)])\n",
    "dyclee = SerialDyClee(phi=0.09, context=context, t_global=1024)\n",
    "results = dyclee.run_dataset(data=horse_aug_flat)\n",
    "results = strip_labels(results)\n",
    "\n",
    "timestamps, snapshots_ordered = unpack_snapshots(dyclee.snapshots)\n",
    "print(snapshots_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seg_img = np.vstack([colors[px] for px in results]).reshape(32,32, 3)\n",
    "plt.imshow(seg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird2 = x_train[18]\n",
    "plt.imshow(bird2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bird2_norm = normalize(bird2)\n",
    "bird2_norm_aug = augment_location(bird2_norm)\n",
    "bird2_aug_flat = flatten_img(bird2_norm_aug)\n",
    "\n",
    "context = np.vstack([bird2_aug_flat.min(axis=0), bird2_aug_flat.max(axis=0)])\n",
    "dyclee = SerialDyClee(phi=0.09, context=context, t_global=1024)\n",
    "results = dyclee.run_dataset(data=bird2_aug_flat)\n",
    "results = strip_labels(results)\n",
    "\n",
    "timestamps, snapshots_ordered = unpack_snapshots(dyclee.snapshots)\n",
    "print(snapshots_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_img = np.vstack([colors[px] for px in results]).reshape(32,32, 3)\n",
    "plt.imshow(seg_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
